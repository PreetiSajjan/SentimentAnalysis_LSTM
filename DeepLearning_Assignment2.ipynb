{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearning Assignment2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AK9izaAHg_he",
        "colab_type": "code",
        "outputId": "868df6f1-6bc5-4fcd-c7e9-b1ce92a400dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "#Importing all the requisite Libraries \n",
        "import csv\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from nltk import word_tokenize\n",
        "nltk.download('wordnet')\n",
        "import spacy\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Dropout\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from keras.layers import Dense,Dropout,Embedding,LSTM,Flatten,GRU,SpatialDropout1D,Bidirectional\n",
        "import gensim\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from sklearn.metrics import classification_report\n",
        "encoder = LabelEncoder()\n",
        "lemma = WordNetLemmatizer()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkXXDo3vics5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Dataset/IMDB Dataset.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8PSSZi6k-ju",
        "colab_type": "code",
        "outputId": "3ed553a1-752d-4fc8-f8fa-954bacda3b4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#Doing the preprocessing.\n",
        "df.isnull().sum() #checking if we have any NULL values\n",
        "df.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqTConiNnBfn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "creating a dictionary for abbreviated terms which will be used to pre process the data\n",
        "'''\n",
        "\n",
        "s_dict = {\n",
        "\"aren't\" : \"are not\",\n",
        "\"can't\" : \"cannot\",\n",
        "\"couldn't\" : \"could not\",\n",
        "\"didn't\" : \"did not\",\n",
        "\"doesn't\" : \"does not\",\n",
        "\"don't\" : \"do not\",\n",
        "\"hadn't\" : \"had not\",\n",
        "\"hasn't\" : \"has not\",\n",
        "\"haven't\" : \"have not\",\n",
        "\"he'd\" : \"he would\",\n",
        "\"he'll\" : \"he will\",\n",
        "\"he's\" : \"he is\",\n",
        "\"i'd\" : \"I would\",\n",
        "\"i'd\" : \"I had\",\n",
        "\"i'll\" : \"I will\",\n",
        "\"i'm\" : \"I am\",\n",
        "\"isn't\" : \"is not\",\n",
        "\"it's\" : \"it is\",\n",
        "\"it'll\":\"it will\",\n",
        "\"i've\" : \"I have\",\n",
        "\"let's\" : \"let us\",\n",
        "\"mightn't\" : \"might not\",\n",
        "\"mustn't\" : \"must not\",\n",
        "\"shan't\" : \"shall not\",\n",
        "\"she'd\" : \"she would\",\n",
        "\"she'll\" : \"she will\",\n",
        "\"she's\" : \"she is\",\n",
        "\"shouldn't\" : \"should not\",\n",
        "\"that's\" : \"that is\",\n",
        "\"there's\" : \"there is\",\n",
        "\"they'd\" : \"they would\",\n",
        "\"they'll\" : \"they will\",\n",
        "\"they're\" : \"they are\",\n",
        "\"they've\" : \"they have\",\n",
        "\"we'd\" : \"we would\",\n",
        "\"we're\" : \"we are\",\n",
        "\"weren't\" : \"were not\",\n",
        "\"we've\" : \"we have\",\n",
        "\"what'll\" : \"what will\",\n",
        "\"what're\" : \"what are\",\n",
        "\"what's\" : \"what is\",\n",
        "\"what've\" : \"what have\",\n",
        "\"where's\" : \"where is\",\n",
        "\"who'd\" : \"who would\",\n",
        "\"who'll\" : \"who will\",\n",
        "\"who're\" : \"who are\",\n",
        "\"who's\" : \"who is\",\n",
        "\"who've\" : \"who have\",\n",
        "\"won't\" : \"will not\",\n",
        "\"wouldn't\" : \"would not\",\n",
        "\"you'd\" : \"you would\",\n",
        "\"you'll\" : \"you will\",\n",
        "\"you're\" : \"you are\",\n",
        "\"you've\" : \"you have\",\n",
        "\"'re\": \" are\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'll\":\" will\",\n",
        "\"didn't\": \"did not\"\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3iTi83Oih73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "The function preprocess() actually helps us to do all the pre processing steps one by one and returns a processed text\n",
        "'''\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess(text):\n",
        "  text = text.lower()\n",
        "  text = \" \".join([s_dict[word] if word in s_dict else word for word in text.split()])\n",
        "  text = \" \".join([lemma.lemmatize(word) for word in word_tokenize(text)])\n",
        "  text = re.sub(r'\\W',' ',text)\n",
        "  text = re.sub(r'\\s+',' ',text)\n",
        "  text = \" \".join([i for i in text.split() if i not in STOPWORDS])\n",
        "  return text\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LmhXQwWi5YI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "'''\n",
        "Calling the necessary functions for pre processing\n",
        "'''\n",
        "df['processed text'] = df['review'].apply(lambda x:preprocess(x))\n",
        "df['tokenized_sents'] = df['processed text'].apply(lambda row:word_tokenize(row))\n",
        "df['sentiment']=encoder.fit_transform(df['sentiment'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVgnOzlS5oxE",
        "colab_type": "code",
        "outputId": "a1fae8d9-23d6-4659-feee-f4dba4a64ba1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>processed text</th>\n",
              "      <th>tokenized_sents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>1</td>\n",
              "      <td>one reviewer ha mentioned watching 1 oz episod...</td>\n",
              "      <td>[one, reviewer, ha, mentioned, watching, 1, oz...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>1</td>\n",
              "      <td>wonderful little production br br filming tech...</td>\n",
              "      <td>[wonderful, little, production, br, br, filmin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>1</td>\n",
              "      <td>thought wa wonderful way spend time hot summer...</td>\n",
              "      <td>[thought, wa, wonderful, way, spend, time, hot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>0</td>\n",
              "      <td>basically family little boy jake think zombie ...</td>\n",
              "      <td>[basically, family, little, boy, jake, think, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>1</td>\n",
              "      <td>petter mattei love time money visually stunnin...</td>\n",
              "      <td>[petter, mattei, love, time, money, visually, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  ...                                    tokenized_sents\n",
              "0  One of the other reviewers has mentioned that ...  ...  [one, reviewer, ha, mentioned, watching, 1, oz...\n",
              "1  A wonderful little production. <br /><br />The...  ...  [wonderful, little, production, br, br, filmin...\n",
              "2  I thought this was a wonderful way to spend ti...  ...  [thought, wa, wonderful, way, spend, time, hot...\n",
              "3  Basically there's a family where a little boy ...  ...  [basically, family, little, boy, jake, think, ...\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  ...  [petter, mattei, love, time, money, visually, ...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q0hx4dyRwtz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "We are calling word2vec model to train the embedding layer\n",
        "'''\n",
        "review_lines = df['tokenized_sents'].values\n",
        "embbed_model = gensim.models.Word2Vec(sentences = review_lines,size = 100,window=5,workers=4,min_count=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixwS0UOfqTlD",
        "colab_type": "code",
        "outputId": "89174e13-df7b-4a1c-f125-23297df6c8f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "embbed_model.wv.most_similar('nice')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('good', 0.6844138503074646),\n",
              " ('neat', 0.676488995552063),\n",
              " ('cool', 0.6455390453338623),\n",
              " ('interesting', 0.6008448600769043),\n",
              " ('great', 0.5883601903915405),\n",
              " ('odd', 0.5803523063659668),\n",
              " ('refreshing', 0.57901930809021),\n",
              " ('pleasant', 0.5698761343955994),\n",
              " ('wonderful', 0.5456319451332092),\n",
              " ('cute', 0.5330506563186646)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcYrJDFEYTYW",
        "colab_type": "code",
        "outputId": "8606a643-68a5-4efb-9c93-10126230eae5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "filename = '/content/drive/My Drive/word2vec_imdb.txt'\n",
        "embbed_model.wv.save_word2vec_format(filename,binary = False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:410: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcgvVwOql8N0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "We are again creating the word dictionary of our dataset and then creating\n",
        "sequence of numbers for all the sentences and then we are doing the padding \n",
        "to make all the input data uniform.\n",
        "'''\n",
        "\n",
        "MAX_NB_WORDS = 10000\n",
        "MAX_SEQUENCE_LENGTH = 100\n",
        "EMBEDDING_DIM = 100\n",
        "tokenizer = Tokenizer(oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(df['processed text'].values)\n",
        "word_index = tokenizer.word_index\n",
        "X = tokenizer.texts_to_sequences(df['processed text'].values)\n",
        "Padded_X = pad_sequences(X,maxlen=MAX_SEQUENCE_LENGTH,padding='post')\n",
        "Y = df['sentiment'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIudYm2waY7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "We are creating our embedding matrix with the use of \n",
        "pretrained coeficients of word2vec model\n",
        "'''\n",
        "\n",
        "embeding_index = {}\n",
        "import os\n",
        "import numpy as np\n",
        "file = open(os.path.join('','/content/drive/My Drive/word2vec_imdb.txt'),encoding='utf-8')\n",
        "for line in file :\n",
        "  values = line.split()\n",
        "  word = values[0]\n",
        "  coefs = np.asarray(values[1:])\n",
        "  embeding_index[word] = coefs\n",
        "\n",
        "num_words = len(word_index)+1\n",
        "embedding_matrix_w2v = np.zeros((num_words,100))\n",
        "\n",
        "for word,i in word_index.items():\n",
        "  if i > num_words:\n",
        "    continue\n",
        "  emd_v = embeding_index.get(word)\n",
        "  if emd_v is not None:\n",
        "    embedding_matrix_w2v[i] =  emd_v\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in9vNbgimrgy",
        "colab_type": "code",
        "outputId": "883174ce-6fd5-41b3-9055-918312e0bdc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embedding_matrix_w2v.shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(95081, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHXA0A4RiLzC",
        "colab_type": "code",
        "outputId": "92997708-40b0-4281-8250-13df583e84fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('shape of Review tensor:',Padded_X.shape)\n",
        "print('Shape of sentiment shape:',Y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of Review tensor: (50000, 100)\n",
            "Shape of sentiment shape: (50000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Iyoj_gsfX9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(Padded_X,Y, test_size = 0.3, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gG7L4pkhItp",
        "colab_type": "code",
        "outputId": "807c7352-7641-483c-df18-182b49138128",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Shape of XTrain{},XTest{},YTrain{},Ytest{}:'.format(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of XTrain(35000, 100),XTest(15000, 100),YTrain(35000,),Ytest(15000,):\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKYpQoNEhKDa",
        "colab_type": "code",
        "outputId": "345fae34-4a73-48f0-ea2e-52d14597acc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "'''\n",
        "our RNN model\n",
        "'''\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(num_words, EMBEDDING_DIM,weights=[embedding_matrix_w2v], input_length=MAX_SEQUENCE_LENGTH))\n",
        "model.add(SpatialDropout1D(0.25))\n",
        "model.add(Bidirectional(LSTM(100)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 100, 100)          9508100   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, 100, 100)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 200)               160800    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 201       \n",
            "=================================================================\n",
            "Total params: 9,669,101\n",
            "Trainable params: 9,669,101\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaQ81WY9kJy7",
        "colab_type": "code",
        "outputId": "4fec9418-f914-448e-b392-c07dfb166283",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "'''\n",
        "Here we are training our RNN model and stopping the training once \n",
        "our training accuracy reaches 96% to avoid overfitting\n",
        "'''\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.96):\n",
        "      print(\"\\nReached 96% accuracy so cancelling training!!!.Stopping the training to avoid overfitting\")\n",
        "      self.model.stop_training = True\n",
        "callbacks = myCallback()\n",
        "epochs = 10\n",
        "batch_size = 64\n",
        "history = model.fit(X_train, Y_train, epochs=epochs,\n",
        "                    validation_split=0.1,verbose=1,callbacks = [callbacks])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 31500 samples, validate on 3500 samples\n",
            "Epoch 1/10\n",
            "31500/31500 [==============================] - 499s 16ms/step - loss: 0.3855 - accuracy: 0.8272 - val_loss: 0.2841 - val_accuracy: 0.8883\n",
            "Epoch 2/10\n",
            "31500/31500 [==============================] - 493s 16ms/step - loss: 0.2641 - accuracy: 0.8946 - val_loss: 0.2633 - val_accuracy: 0.8897\n",
            "Epoch 3/10\n",
            "31500/31500 [==============================] - 490s 16ms/step - loss: 0.1770 - accuracy: 0.9321 - val_loss: 0.2809 - val_accuracy: 0.8951\n",
            "Epoch 4/10\n",
            "31500/31500 [==============================] - 489s 16ms/step - loss: 0.1000 - accuracy: 0.9643 - val_loss: 0.3154 - val_accuracy: 0.8900\n",
            "\n",
            "Reached 96% accuracy so cancelling training!!!.Stopping the training to avoid overfitting\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSGjRNclth64",
        "colab_type": "code",
        "outputId": "b0ee42b6-3594-4861-cb0d-74047dab5c36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print('Evaluating the model with Test data')\n",
        "Model_test = model.evaluate(X_test,Y_test,batch_size =128 )\n",
        "print('test loss, test acc:', Model_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating the model with Test data\n",
            "15000/15000 [==============================] - 4s 296us/step\n",
            "test loss, test acc: [0.3204834939400355, 0.8875333070755005]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMlLb1W5m9mj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted = model.predict_classes(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HV5JL6anGjl",
        "colab_type": "code",
        "outputId": "e7828b29-fe44-4449-b14a-7f4d4391cacb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "print(classification_report(Y_test, predicted))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.90      0.89      7411\n",
            "           1       0.90      0.88      0.89      7589\n",
            "\n",
            "    accuracy                           0.89     15000\n",
            "   macro avg       0.89      0.89      0.89     15000\n",
            "weighted avg       0.89      0.89      0.89     15000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ0xSj_cD8Ov",
        "colab_type": "code",
        "outputId": "93126a60-6870-4e46-dfe7-a198488aeffd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''\n",
        "Creation of basic LR model with count vectorizer.\n",
        "'''\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer ,CountVectorizer \n",
        "cv = CountVectorizer(ngram_range=(1,2), binary =True, min_df = 10000)\n",
        "X = cv.fit_transform(df['processed text'].values).toarray()\n",
        "Y = df['sentiment'].values\n",
        "X_train2, X_test2, Y_train2, Y_test2 = train_test_split(X,Y, test_size = 0.3, random_state = 42)\n",
        "print('Shape of XTrain{},XTest{},YTrain{},Ytest{}:'.format(X_train2.shape,X_test2.shape,Y_train2.shape,Y_test2.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of XTrain(35000, 44),XTest(15000, 44),YTrain(35000,),Ytest(15000,):\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXjn-e4Qbfa2",
        "colab_type": "code",
        "outputId": "b96a9561-a907-49b9-d36b-b3211f7d8b37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train2,Y_train2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Js8QldgNf_n1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = lr.predict(X_test2)\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-7KtM1XgFZk",
        "colab_type": "code",
        "outputId": "5aee9659-ee9a-411a-ce39-c0021d3808e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "print(classification_report(Y_test2, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.67      0.68      7411\n",
            "           1       0.69      0.71      0.70      7589\n",
            "\n",
            "    accuracy                           0.69     15000\n",
            "   macro avg       0.69      0.69      0.69     15000\n",
            "weighted avg       0.69      0.69      0.69     15000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1GU2I-hgTrj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "predict_review() and predict_review_RNN() help us to get a prediction value \n",
        "when we pass a review statement to these functions\n",
        "'''\n",
        "def predict_review(review):\n",
        "    rvw = preprocess(review)\n",
        "    x_rvw= cv.transform([rvw])\n",
        "    review_predict = lr.predict(x_rvw)\n",
        "    if review_predict == 0:\n",
        "      print('Bag of Words Model says User Marked it [Negative]')\n",
        "    else:\n",
        "      print('Bag of Words Model says User Marked it [Positive]')\n",
        "\n",
        "def predict_review_RNN(review):\n",
        "    rvw = preprocess(review)\n",
        "    x_rvw= tokenizer.texts_to_sequences([rvw])\n",
        "    fd = pad_sequences(x_rvw,maxlen=MAX_SEQUENCE_LENGTH,padding='post')\n",
        "    review_predict = model.predict_classes(fd)\n",
        "    if review_predict == 0:\n",
        "      print('Deep RNN model says User Marked it [negative]')\n",
        "    else:\n",
        "      print('Deep RNN model says User Marked it [Positive]')\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UDuBSstBTlb",
        "colab_type": "code",
        "outputId": "f0c31ddd-e784-4c60-f035-4fdca0215f59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "predict_review(\"How can I forget the movie. This was really wonderful and cunning.I never want to forget such a beautiful movie\")\n",
        "predict_review_RNN(\"How can I forget the movie. This was really wonderful and cunning.I never want to forget such a beautiful movie\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bag of Words Model says User Marked it [Negative]\n",
            "Deep RNN model says User Marked it [Positive]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tlc0cejjkhb1",
        "colab_type": "code",
        "outputId": "0e7c8918-5692-47ab-b642-4b05aef9ed4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "predict_review(\"Despite the wonderfully packaging, the product was poor\")\n",
        "predict_review_RNN(\"Despite the wonderfully packaging, the product was poor\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bag of Words Model says User Marked it [Positive]\n",
            "Deep RNN model says User Marked it [negative]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPkPiAB4C9IC",
        "colab_type": "code",
        "outputId": "5f47fbdc-9e55-4943-c7ef-64dee5ef7fdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predict_review_RNN(\"The excellent acting and soundtrack could not save this movie.\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deep RNN model says User Marked it [negative]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdWttcsqDp-L",
        "colab_type": "code",
        "outputId": "95f03b26-d342-4132-b760-1fc4b0fa837a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predict_review_RNN(\"There are some outstanding and great performance but still the movie is streched to boredom\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deep RNN model says User Marked it [Positive]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktafG9OJDMuQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}